import{_ as o}from"./chunks/daqianai-header.CFdivPrw.js";import{_ as k}from"./chunks/daqianai_wx_qrcode_white.eXbCYHnq.js";import{_ as E,C as d,c as g,o as t,a2 as p,b as e,j as i,w as n,a as s,G as h,a3 as r}from"./chunks/framework.DDIT__tB.js";const f=JSON.parse('{"title":"拒绝重复造轮子！LangChain如何简化LLM应用开发？","description":"","frontmatter":{"title":"拒绝重复造轮子！LangChain如何简化LLM应用开发？"},"headers":[],"relativePath":"blog/langchain-introduction.md","filePath":"blog/langchain-introduction.md","lastUpdated":1748782171000}'),c={name:"blog/langchain-introduction.md"};function u(A,a,m,C,F,b){const l=d("Mermaid");return t(),g("div",null,[a[4]||(a[4]=p('<p><img src="'+o+'" alt="大千世界无奇不有，大千AI智探万象"></p><blockquote><p>开发者困境：</p><ol><li>每次切换GPT-4→Claude就像重装操作系统</li><li>想把&quot;摘要生成&quot;和&quot;情感分析&quot;串联起来？先写200行胶水代码</li><li>想加个网络搜索功能？从零开始造轮子</li></ol></blockquote><p>LangChain的诞生正是为了解决这些LLM开发的&#39;脏活累活&#39;。</p><h1 id="langchain-introduction" tabindex="-1">LangChain Introduction <a class="header-anchor" href="#langchain-introduction" aria-label="Permalink to &quot;LangChain Introduction&quot;">​</a></h1><blockquote><p>LangChain是一个应用开发框架，专注于由LLM驱动的AI应用开发。 可以简化开发的每一个阶段。</p></blockquote><h2 id="基本功能" tabindex="-1">基本功能 <a class="header-anchor" href="#基本功能" aria-label="Permalink to &quot;基本功能&quot;">​</a></h2><blockquote><p>核心 = 大脑 + 躯体</p></blockquote><ul><li>大脑: 提供了一套标准接口，可用来和各种LLM提供商的接口进行交互</li><li>躯体: 提供了一套通用的可组合的组件，可用来快速构建复杂的LLM驱动的AI应用</li></ul><h2 id="关键能力" tabindex="-1">关键能力 <a class="header-anchor" href="#关键能力" aria-label="Permalink to &quot;关键能力&quot;">​</a></h2><ul><li>Model Interoperability(模型热插拔) - 🔌像更换手机SIM卡一样切换大模型——只需修改配置，无需重写代码</li><li>Composability(组件可组合性) - 通过LangChain表达式语言(LCEL)轻松将各种标准组件连接在一起</li><li>Real-time Data Augmentation(实时数据增强) - 可轻松地将LLM连接到外部数据源和工具从而实现实时的数据增强</li><li>Agent Creation(智能体创建) - 能够用来创建可自主使用工具和做决策的智能体</li></ul>',10)),(t(),e(r,null,{default:n(()=>[h(l,{id:"mermaid-81",class:"mermaid",graph:"flowchart%20TB%0A%20%20subgraph%20%22LangChain%E5%85%B3%E9%94%AE%E8%83%BD%E5%8A%9B%22%0A%20%20%20%20direction%20TB%0A%20%20%20%20model(Model%20Interoperability)%0A%20%20%20%20component(Component%20Composability)%0A%20%20%20%20data(Data%20Source%20Connections)%0A%20%20%20%20agent(Agent%20Construction)%0A%0A%20%20%20%20feature(Simplify%20Application%20Development)%0A%0A%20%20%20%20model%20--%3E%20feature%0A%20%20%20%20component%20--%3E%20feature%0A%20%20%20%20data%20--%3E%20feature%0A%20%20%20%20agent%20--%3E%20feature%0A%20%20end%0A"})]),fallback:n(()=>a[0]||(a[0]=[s(" Loading... ")])),_:1})),a[5]||(a[5]=p('<h2 id="整体架构" tabindex="-1">整体架构 <a class="header-anchor" href="#整体架构" aria-label="Permalink to &quot;整体架构&quot;">​</a></h2><p>LangChain整体采用模块化架构，各模块职责清晰。该架构不仅易扩展、易集成(与各种LLM供应商集成)，同时还保持了接口的一致性。</p><h3 id="package-structure" tabindex="-1">Package Structure <a class="header-anchor" href="#package-structure" aria-label="Permalink to &quot;Package Structure&quot;">​</a></h3><blockquote><p>▲ LangChain生态像拼积木一样，主要包括：</p><ul><li>基础块（core）</li><li>高级功能块（langchain）</li><li>社区扩展块（community）</li><li>按需取用，自由拼接</li></ul></blockquote>',4)),(t(),e(r,null,{default:n(()=>[h(l,{id:"mermaid-118",class:"mermaid",graph:"flowchart%20LR%0A%20%20A%5B%5BLangChain%E7%94%9F%E6%80%81%5D%5D%20--%3E%20B%5B%22%F0%9F%94%92%20%E5%9F%BA%E7%A1%80%E7%A7%AF%E6%9C%A8%E5%9D%97%3C%2Fbr%3Elangchain-core%22%5D%0A%20%20A%20--%3E%20C%5B%22%F0%9F%9A%80%20%E9%AB%98%E7%BA%A7%E7%BB%84%E4%BB%B6%3C%2Fbr%3Elangchain%22%5D%0A%20%20A%20--%3E%20D%5B%22%F0%9F%8C%88%20%E7%A4%BE%E5%8C%BA%E6%89%A9%E5%B1%95%3C%2Fbr%3Elangchain-community%22%5D%0A%20%20A%20--%3E%20E%5B%22%F0%9F%A5%8A%20%E4%B8%89%E6%96%B9%E9%9B%86%E6%88%90%3C%2Fbr%3EIntegration%20packages%22%5D%0A%20%20A%20--%3E%20F%5B%22%F0%9F%8E%AC%20%E5%A4%8D%E6%9D%82%E7%BC%96%E6%8E%92%E5%B7%A5%E5%85%B7%3C%2Fbr%3Elanggraph%22%5D%0A%20%20B%20--%3E%7CLCEL%E5%8E%9F%E8%AF%AD%7C%20C%0A%20%20D%20--%3E%7C%E9%9B%86%E6%88%90%7C%20C%0A%20%20E%20--%3E%7C%E9%9B%86%E6%88%90%7C%20C%0A"})]),fallback:n(()=>a[1]||(a[1]=[s(" Loading... ")])),_:1})),a[6]||(a[6]=i("blockquote",null,[i("p",null,"LangChain生态由多个包组成,每一个都有特定的作用")],-1)),a[7]||(a[7]=i("ul",null,[i("li",null,"langchain-core: 最核心最基本的抽象和LCEL原语(LangChain表达式语言)"),i("li",null,"langchain: 提供高级抽象(比如chains、agents、RAG等)"),i("li",null,"langchain-community: 包含社区维护的第三方集成工具(比如文档加载器、向量存储等)"),i("li",null,"Integration packages: 主流LLM提供商的接口的专有集成包(比如OpenAI, Anthropic等)"),i("li",null,"langgraph: 用于将LangChain组件组合编排成产品级应用程序的框架")],-1)),(t(),e(r,null,{default:n(()=>[h(l,{id:"mermaid-151",class:"mermaid",graph:"flowchart%20LR%0A%20%20subgraph%20%22Integration%20packages%22%0A%20%20%20%20direction%20TB%0A%20%20%20%20%20%20langchain-openai%0A%20%20%20%20%20%20langchain-anthropic%0A%20%20%20%20%20%20langchain-groq%0A%20%20%20%20%20%20langchain-fireworks%0A%20%20%20%20%20%20more_provider_package(...more%20provider%20packages)%0A%20%20end%0A"})]),fallback:n(()=>a[2]||(a[2]=[s(" Loading... ")])),_:1})),a[8]||(a[8]=i("ul",null,[i("li",null,"主流LLM提供商的专有集成包")],-1)),a[9]||(a[9]=i("h3",{id:"runnable接口和lcel",tabindex:"-1"},[s("Runnable接口和LCEL "),i("a",{class:"header-anchor",href:"#runnable接口和lcel","aria-label":'Permalink to "Runnable接口和LCEL"'},"​")],-1)),a[10]||(a[10]=i("ul",null,[i("li",null,[i("strong",null,"Runnable"),s("接口是LangChain设计的基石, 实现了与所有组件的标准化交互, 并通过LCEL实现各组件的组合")])],-1)),(t(),e(r,null,{default:n(()=>[h(l,{id:"mermaid-169",class:"mermaid",graph:"classDiagram%0A%20%20note%20for%20Runnable%20%22%E6%89%80%E6%9C%89%E5%8A%9F%E8%83%BD%E7%9A%84'%E4%B8%87%E8%83%BD%E6%8F%92%E5%BA%A7'%22%0A%20%20note%20%22%E6%89%80%E6%9C%89%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%E9%83%BD%E5%AE%9E%E7%8E%B0Runnable%E6%8E%A5%E5%8F%A3%22%0A%0A%20%20class%20Runnable%5B%22%26lt%26ltinterface%26gt%26gt%3C%2Fbr%3E%20Runnable%22%5D%20%7B%0A%20%20%20%20%2Binvoke(input)%0A%20%20%20%20%2Bstream(input)%0A%20%20%20%20%2Bbatch(inputs)%0A%20%20%20%20%2Bainvoke(input)%0A%20%20%20%20%2Bastream(input)%0A%20%20%20%20%2Babatch(inputs)%0A%20%20%20%20%2Btransform(func)%0A%20%20%20%20%2Batransform(func)%0A%20%20%7D%0A%20%20Runnable%20%3C%7C--%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%0A%20%20Runnable%20%3C%7C--%20%E6%8F%90%E7%A4%BA%E8%AF%8D%0A%20%20Runnable%20%3C%7C--%20%E5%B7%A5%E5%85%B7%0A%20%20Runnable%20%3C%7C--%20%E8%AE%B0%E5%BF%86%E6%A8%A1%E5%9D%97%0A"})]),fallback:n(()=>a[3]||(a[3]=[s(" Loading... ")])),_:1})),a[11]||(a[11]=p(`<p>通过统一的<strong>Runnable</strong>抽象实现了</p><ul><li>统一的调用接口: 所有组件通过标准方法集(<code>invoke/ainvoke, stream/astream, batch/abatch</code>)提供一致的使用体验</li><li>并行化: 批处理操作<code>batch</code></li><li>异步支持: <code>a</code>(async)开头的方法<code>ainvoke, astream, abatch</code>等</li><li>可组合性: 通过pipe语法实现各组件的组合</li></ul><h2 id="实战对比" tabindex="-1">实战对比 <a class="header-anchor" href="#实战对比" aria-label="Permalink to &quot;实战对比&quot;">​</a></h2><h3 id="传统开发-vs-langchain开发" tabindex="-1">传统开发 vs LangChain开发 <a class="header-anchor" href="#传统开发-vs-langchain开发" aria-label="Permalink to &quot;传统开发 vs LangChain开发&quot;">​</a></h3><blockquote><p>在评论区留下你的LLM开发痛点，我们会针对性解答</p></blockquote><table tabindex="0"><thead><tr><th>痛苦场景</th><th>传统开发</th><th>LangChain方案</th><th>省力程度</th></tr></thead><tbody><tr><td>模型迁移</td><td>重构所有API调用</td><td>修改<code>llm = ChatOpenAI()</code>→<code>llm = ChatAnthropic()</code></td><td>⏱️ 节省80%时间</td></tr><tr><td>功能流水线</td><td>手动处理JSON格式转换</td><td><code>chain = prompt | model | parser</code></td><td>🧩 代码减少70%</td></tr></tbody></table><h3 id="🚀-实践建议" tabindex="-1">🚀 实践建议： <a class="header-anchor" href="#🚀-实践建议" aria-label="Permalink to &quot;🚀 实践建议：&quot;">​</a></h3><p>🔥 <strong>5分钟快速验证</strong>：</p><ol><li>安装核心包：</li></ol><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> install</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;langchain-core&gt;=0.2.0&quot;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> langchain-openai</span></span></code></pre></div><ol start="2"><li>快速验证</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_core.prompts </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatPromptTemplate</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> langchain_openai </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">prompt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatPromptTemplate.from_template(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;帮我用</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{style}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">的风格写一篇关于</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{topic}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">的文案&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 可以通过设置 api_key 和 base_url 参数使用</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">api_key </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;使用的LLM的api key&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">base_url </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;使用的LLM的 api 地址&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">llm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ChatOpenAI(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">model</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-4&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">api_key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">api_key, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">base_url</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">base_url)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">chain </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> prompt </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">|</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> llm</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(chain.invoke({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;style&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;幽默&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;topic&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;AI&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}))</span></span></code></pre></div><p>⚠️ 注意：LangChain仍在快速迭代，生产环境建议锁定版本号</p><h2 id="reference" tabindex="-1">Reference <a class="header-anchor" href="#reference" aria-label="Permalink to &quot;Reference&quot;">​</a></h2><ul><li><a href="https://python.langchain.com/docs/introduction/" target="_blank" rel="noreferrer">https://python.langchain.com/docs/introduction/</a></li><li><a href="https://deepwiki.com/langchain-ai/langchain" target="_blank" rel="noreferrer">https://deepwiki.com/langchain-ai/langchain</a></li></ul><p><img src="`+k+'" alt="微信搜索 &quot;大千AI助手&quot; 学习最实用的AI技术"></p>',16))])}const q=E(c,[["render",u]]);export{f as __pageData,q as default};
