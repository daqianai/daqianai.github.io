import{_ as n,c as t,o as l,ag as e,j as i,a,t as o}from"./chunks/framework.BDwTZuFy.js";const E=JSON.parse('{"title":"Reinforcement fine-tuning","description":"","frontmatter":{},"headers":[],"relativePath":"docs/openai/guides/reinforcement-fine-tuning.md","filePath":"docs/openai/guides/reinforcement-fine-tuning.md","lastUpdated":1748071461000}'),r={name:"docs/openai/guides/reinforcement-fine-tuning.md"};function h(p,s,d,k,c,u){return l(),t("div",null,[s[6]||(s[6]=e(`<h1 id="reinforcement-fine-tuning" tabindex="-1">Reinforcement fine-tuning <a class="header-anchor" href="#reinforcement-fine-tuning" aria-label="Permalink to &quot;Reinforcement fine-tuning&quot;">​</a></h1><p>Fine-tune models for expert-level performance within a domain.</p><p>Reinforcement fine-tuning (RFT) adapts an OpenAI reasoning model with a feedback signal you define. Like <a href="/docs/openai/guides/supervised-fine-tuning.html">supervised fine-tuning</a>, it tailors the model to your task. The difference is that instead of training on fixed “correct” answers, it relies on a programmable grader that scores every candidate response. The training algorithm then shifts the model’s weights, so high-scoring outputs become more likely and low-scoring ones fade.</p><p>This optimization lets you align the model with nuanced objectives like style, safety, or domain accuracy—with many <a href="/docs/openai/guides/rft-use-cases.html">practical use cases</a> emerging. Run RFT in five steps:</p><ol><li>Implement a <a href="/docs/openai/guides/graders.html">grader</a> that assigns a numeric reward to each model response.</li><li>Upload your prompt dataset and designate a validation split.</li><li>Start the fine-tune job.</li><li>Monitor and <a href="/docs/openai/guides/evals.html">evaluate</a> checkpoints; revise data or grader if needed.</li><li>Deploy the resulting model through the standard API.</li></ol><p>During training, the platform cycles through the dataset, samples several responses per prompt, scores them with the grader, and applies policy-gradient updates based on those rewards. The loop continues until we hit the end of your training data or you stop the job at a chosen checkpoint, producing a model optimized for the metric that matters to you.</p><p>When should I use reinforcement fine-tuning?</p><p>It&#39;s useful to understand the strengths and weaknesses of reinforcement fine-tuning to identify opportunities and to avoid wasted effort.</p><ul><li><strong>RFT works best with unambiguous tasks</strong>. Check whether qualified human experts agree on the answers. If conscientious experts working independently (with access only to the same instructions and information as the model) do not converge on the same answers, the task may be too ambiguous and may benefit from revision or reframing.</li><li><strong>Your task must be compatible with the grading options</strong>. Review <a href="/docs/api-reference/graders.html">grading options in the API</a> first and verify it&#39;s possible to grade your task with them.</li><li><strong>Your eval results must be variable enough to improve</strong>. Run <a href="/docs/openai/guides/evals.html">evals</a> before using RFT. If your eval scores between minimum and maximum possible scores, you&#39;ll have enough data to work with to reinforce positive answers. If the model you want to fine-tune scores at either the absolute minimum or absolute maximum score, RFT won&#39;t be useful to you.</li><li><strong>Your model must have some success at the desired task</strong>. Reinforcement fine-tuning makes gradual changes, sampling many answers and choosing the best ones. If a model has a 0% success rate at a given task, you cannot bootstrap to higher performance levels through RFT.</li><li><strong>Your task should be guess-proof</strong>. If the model can get a higher reward from a lucky guess, the training signal is too noisy, as the model can get the right answer with an incorrect reasoning process. Reframe your task to make guessing more difficult—for example, by expanding classes into subclasses or revising a multiple choice problem to take open-ended answers.</li></ul><p>See common use cases, specific implementations, and grader examples in the <a href="/docs/openai/guides/rft-use-cases.html">reinforcement fine-tuning use case guide</a>.</p><p>What is reinforcement learning?</p><p>Reinforcement learning is a branch of machine learning in which a model learns by acting, receiving feedback, and readjusting itself to maximise future feedback. Instead of memorising one “right” answer per example, the model explores many possible answers, observes a numeric reward for each, and gradually shifts its behaviour so the high-reward answers become more likely and the low-reward ones disappear. Over repeated rounds, the model converges on a policy—a rule for choosing outputs—that best satisfies the reward signal you define.</p><p>In reinforcement fine-tuning (RFT), that reward signal comes from a custom grader that you define for your task. For every prompt in your dataset, the platform samples multiple candidate answers, runs your grader to score them, and applies a policy-gradient update that nudges the model toward answers with higher scores. This cycle—sample, grade, update—continues across the dataset (and successive epochs) until the model reliably optimizes for your grader’s understanding of quality. The grader encodes whatever you care about—accuracy, style, safety, or any metric—so the resulting fine-tuned model reflects those priorities and you don&#39;t have to manage reinforcement learning infrastructure.</p><p>Reinforcement fine-tuning is supported on o-series reasoning models only, and currently only for <a href="/docs/models/o4-mini.html">o4-mini</a>.</p><h2 id="example-llm-powered-security-review" tabindex="-1">Example: LLM-powered security review <a class="header-anchor" href="#example-llm-powered-security-review" aria-label="Permalink to &quot;Example: LLM-powered security review&quot;">​</a></h2><p>To demonstrate reinforcement fine-tuning below, we&#39;ll fine-tune an <a href="/docs/models/o4-mini.html">o4-mini</a> model to provide expert answers about a fictional company&#39;s security posture, based on an internal company policy document. We want the model to return a JSON object that conforms to a specific schema with <a href="/docs/openai/guides/structured-outputs.html">Structured Outputs</a>.</p><p>Example input question:</p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Do you have a dedicated security team?</span></span></code></pre></div><p>Using the internal policy document, we want the model to respond with JSON that has two keys:</p><ul><li><code>compliant</code>: A string <code>yes</code>, <code>no</code>, or <code>needs review</code>, indicating whether the company&#39;s policy covers the question.</li><li><code>explanation</code>: A string of text that briefly explains, based on the policy document, why the question is covered in the policy or why it&#39;s not covered.</li></ul><p>Example desired output from the model:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;compliant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;yes&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;explanation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;A dedicated security team follows strict protocols for handling incidents.&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Let&#39;s fine-tune a model with RFT to perform well at this task.</p><h2 id="define-a-grader" tabindex="-1">Define a grader <a class="header-anchor" href="#define-a-grader" aria-label="Permalink to &quot;Define a grader&quot;">​</a></h2><p>To perform RFT, define a <a href="/docs/openai/guides/graders.html">grader</a> to score the model&#39;s output during training, indicating the quality of its response. RFT uses the same set of graders as <a href="/docs/openai/guides/evals.html">evals</a>, which you may already be familiar with.</p><p>In this example, we define <a href="/docs/api-reference/graders/multi.html">multiple graders</a> to examine the properties of the JSON returned by our fine-tuned model:</p><ul><li>The <a href="/docs/api-reference/graders/string-check.html"><code>string_check</code></a> grader to ensure the proper <code>compliant</code> property has been set</li><li>The <a href="/docs/api-reference/graders/score-model.html"><code>score_model</code></a> grader to provide a score between zero and one for the explanation text, using another evaluator model</li></ul><p>We weight the output of each property equally in the <code>calculate_output</code> expression.</p>`,28)),i("p",null,[s[0]||(s[0]=a("Below is the JSON payload data we'll use for this grader in API requests. In both graders, we use ")),i("code",null,o(),1),s[1]||(s[1]=a(" template syntax to refer to the relevant properties of both the ")),s[2]||(s[2]=i("code",null,"item",-1)),s[3]||(s[3]=a(" (the row of test data being used for evaluation) and ")),s[4]||(s[4]=i("code",null,"sample",-1)),s[5]||(s[5]=a(" (the model output generated during the training run)."))]),s[7]||(s[7]=e(`<p>Grader configuration</p><p>Multi-grader configuration object</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;multi&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;graders&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;explanation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Explanation text grader&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;score_model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;input&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;message&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;...see other tab for the full prompt...&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      ],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-4o-2024-08-06&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;compliant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;compliant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;string_check&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;reference&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;{{item.compliant}}&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;operation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;eq&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;input&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;{{sample.output_json.compliant}}&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;calculate_output&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;0.5 * compliant + 0.5 * explanation&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Grading prompt</p><p>Grading prompt in the grader config</p><div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;"># Overview</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Evaluate the accuracy of the model-generated answer based on the </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Copernicus Product Security Policy and an example answer. The response </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">should align with the policy, cover key details, and avoid speculative </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">or fabricated claims.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Always respond with a single floating point number 0 through 1,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">using the grading criteria below.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">## Grading Criteria:</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **1.0**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: The model answer is fully aligned with the policy and factually correct.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **0.75**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: The model answer is mostly correct but has minor omissions or slight rewording that does not change meaning.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **0.5**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: The model answer is partially correct but lacks key details or contains speculative statements.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **0.25**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: The model answer is significantly inaccurate or missing important information.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **0.0**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: The model answer is completely incorrect, hallucinates policy details, or is irrelevant.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">## Copernicus Product Security Policy</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Introduction</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Protecting customer data is a top priority for Copernicus. Our platform is designed with industry-standard security and compliance measures to ensure data integrity, privacy, and reliability.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Data Classification</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Copernicus safeguards customer data, which includes prompts, responses, file uploads, user preferences, and authentication configurations. Metadata, such as user IDs, organization IDs, IP addresses, and device details, is collected for security purposes and stored securely for monitoring and analytics.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Data Management</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Copernicus utilizes cloud-based storage with strong encryption (AES-256) and strict access controls. Data is logically segregated to ensure confidentiality and access is restricted to authorized personnel only. Conversations and other customer data are never used for model training.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Data Retention</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Customer data is retained only for providing core functionalities like conversation history and team collaboration. Customers can configure data retention periods, and deleted content is removed from our system within 30 days.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### User Authentication &amp; Access Control</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Users authenticate via Single Sign-On (SSO) using an Identity Provider (IdP). Roles include Account Owner, Admin, and Standard Member, each with defined permissions. User provisioning can be automated through SCIM integration.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Compliance &amp; Security Monitoring</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Compliance API**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Logs interactions, enabling data export and deletion.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Audit Logging**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Ensures transparency for security audits.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **HIPAA Support**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Business Associate Agreements (BAAs) available for customers needing healthcare compliance.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Security Monitoring**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: 24/7 monitoring for threats and suspicious activity.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Incident Response**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: A dedicated security team follows strict protocols for handling incidents.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Infrastructure Security</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Access Controls**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Role-based authentication with multi-factor security.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Source Code Security**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Controlled code access with mandatory reviews before deployment.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Network Security**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Web application firewalls and strict ingress/egress controls to prevent unauthorized access.</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">-</span><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;"> **Physical Security**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: Data centers have controlled access, surveillance, and environmental risk management.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Bug Bounty Program</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Security researchers are encouraged to report vulnerabilities through our Bug Bounty Program for responsible disclosure and rewards.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Compliance &amp; Certifications</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Copernicus maintains compliance with industry standards, including SOC 2 and GDPR. Customers can access security reports and documentation via our Security Portal.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Conclusion</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Copernicus prioritizes security, privacy, and compliance. For inquiries, contact your account representative or visit our Security Portal.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">## Examples</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Example 1: GDPR Compliance</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Reference Answer**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Copernicus maintains compliance with industry standards, including SOC 2 and GDPR. Customers can access security reports and documentation via our Security Portal.&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 1**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Yes, Copernicus is GDPR compliant and provides compliance documentation via the Security Portal.&#39; </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 1.0**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (fully correct)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 2**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Yes, Copernicus follows GDPR standards.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 0.75**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (mostly correct but lacks detail about compliance reports)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 3**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Copernicus may comply with GDPR but does not provide documentation.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 0.5**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (partially correct, speculative about compliance reports)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 4**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Copernicus does not follow GDPR standards.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 0.0**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (factually incorrect)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;">### Example 2: Encryption in Transit</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Reference Answer**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;The Copernicus Product Security Policy states that data is stored with strong encryption (AES-256) and that network security measures include web application firewalls and strict ingress/egress controls. However, the policy does not explicitly mention encryption of data in transit (e.g., TLS encryption). A review is needed to confirm whether data transmission is encrypted.&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 1**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Data is encrypted at rest using AES-256, but a review is needed to confirm encryption in transit.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 1.0**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (fully correct)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 2**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Yes, Copernicus encrypts data in transit and at rest.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 0.5**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (partially correct, assumes transit encryption without confirmation)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 3**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;All data is protected with encryption.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 0.25**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (vague and lacks clarity on encryption specifics)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Model Answer 4**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: &#39;Data is not encrypted in transit.&#39;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-light-font-weight:bold;--shiki-dark:#E1E4E8;--shiki-dark-font-weight:bold;">**Score: 0.0**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (factually incorrect)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Reference Answer: {{item.explanation}}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Model Answer: {{sample.output_json.explanation}}</span></span></code></pre></div><h2 id="prepare-your-dataset" tabindex="-1">Prepare your dataset <a class="header-anchor" href="#prepare-your-dataset" aria-label="Permalink to &quot;Prepare your dataset&quot;">​</a></h2><p>To create an RFT fine-tune, you&#39;ll need both a training and test dataset. Both the training and test datasets will share the same <a href="https://jsonlines.org/" target="_blank" rel="noreferrer">JSONL format</a>. Each line in the JSONL data file will contain a <code>messages</code> array, along with any additional fields required to grade the output from the model. The full specification for RFT dataset <a href="/docs/api-reference/fine-tuning/reinforcement-input.html">can be found here</a>.</p><p>In our case, in addition to the <code>messages</code> array, each line in our JSONL file also needs <code>compliant</code> and <code>explanation</code> properties, which we can use as reference values to test the fine-tuned model&#39;s Structured Output.</p><p>A single line in our training and test datasets looks like this as indented JSON:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;messages&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;role&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;user&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;content&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Do you have a dedicated security team?&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;compliant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;yes&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;explanation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;A dedicated security team follows strict protocols for handling incidents.&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Below, find some JSONL data you can use for both training and testing when you create your fine-tune job. Note that these datasets are for illustration purposes only—in your real test data, strive for diverse and representative inputs for your application.</p><p><strong>Training set</strong></p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Do you have a dedicated security team?&quot;}],&quot;compliant&quot;:&quot;yes&quot;,&quot;explanation&quot;:&quot;A dedicated security team follows strict protocols for handling incidents.&quot;}</span></span>
<span class="line"><span>{&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Have you undergone third-party security audits or penetration testing in the last 12 months?&quot;}],&quot;compliant&quot;:&quot;needs review&quot;,&quot;explanation&quot;:&quot;The policy does not explicitly mention undergoing third-party security audits or penetration testing. It only mentions SOC 2 and GDPR compliance.&quot;}</span></span>
<span class="line"><span>{&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Is your software SOC 2, ISO 27001, or similarly certified?&quot;}],&quot;compliant&quot;:&quot;yes&quot;,&quot;explanation&quot;:&quot;The policy explicitly mentions SOC 2 compliance.&quot;}</span></span></code></pre></div><p><strong>Test set</strong></p><div class="language-text vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">text</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>{&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Will our data be encrypted at rest?&quot;}],&quot;compliant&quot;:&quot;yes&quot;,&quot;explanation&quot;:&quot;Copernicus utilizes cloud-based storage with strong encryption (AES-256) and strict access controls.&quot;}</span></span>
<span class="line"><span>{&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Will data transmitted to/from your services be encrypted in transit?&quot;}],&quot;compliant&quot;:&quot;needs review&quot;,&quot;explanation&quot;:&quot;The policy does not explicitly mention encryption of data in transit. It focuses on encryption in cloud storage.&quot;}</span></span>
<span class="line"><span>{&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;Do you enforce multi-factor authentication (MFA) internally?&quot;}],&quot;compliant&quot;:&quot;yes&quot;,&quot;explanation&quot;:&quot;The policy explicitly mentions role-based authentication with multi-factor security.&quot;}</span></span></code></pre></div><p>How much training data is needed?</p><p>Start small—between several dozen and a few hundred examples—to determine the usefulness of RFT before investing in a large dataset. For product safety reasons, the training set must first pass through an automated screening process. Large datasets take longer to process. This screening process begins when you start a fine-tuning job with a file, not upon initial file upload. Once a file has successfully completed screening, you can use it repeatedly without delay.</p><p>Dozens of examples can be meaningful as long as they&#39;re high quality. After screening, more data is better, as long as it remains high quality. With larger datasets, you can use a higher batch size, which tends to improve training stability.</p><p>Your training file can contain a maximum of 50,000 examples. Test datasets can contain a maximum of 1,000 examples. Test datasets also go through automated screening.</p><h3 id="upload-your-files" tabindex="-1">Upload your files <a class="header-anchor" href="#upload-your-files" aria-label="Permalink to &quot;Upload your files&quot;">​</a></h3><p>The process for uploading RFT training and test data files is the same as <a href="/docs/openai/guides/supervised-fine-tuning.html">supervised fine-tuning</a>. Upload your training data to OpenAI either through the <a href="/docs/api-reference/files/create.html">API</a> or <a href="/storage.html">using our UI</a>. Files must be uploaded with a purpose of <code>fine-tune</code> in order to be used with fine-tuning.</p><p><strong>You need file IDs for both your test and training data files</strong> to create a fine-tune job.</p><h2 id="create-a-fine-tune-job" tabindex="-1">Create a fine-tune job <a class="header-anchor" href="#create-a-fine-tune-job" aria-label="Permalink to &quot;Create a fine-tune job&quot;">​</a></h2><p>Create a fine-tune job using either the <a href="/docs/api-reference/fine-tuning.html">API</a> or <a href="/finetune.html">fine-tuning dashboard</a>. To do this, you need:</p><ul><li>File IDs for both your training and test datasets</li><li>The grader configuration we created earlier</li><li>The model ID you want to use as a base for fine-tuning (we&#39;ll use <code>o4-mini-2025-04-16</code>)</li><li>If you&#39;re fine-tuning a model that will return JSON data as a structured output, you need the JSON schema for the returned object as well (see below)</li><li>Optionally, any hyperparameters you want to configure for the fine-tune</li><li>To qualify for <a href="/docs/pricing.html#fine-tuning">data sharing inference pricing</a>, you need to first <a href="https://help.openai.com/en/articles/10306912-sharing-feedback-evaluation-and-fine-tuning-data-and-api-inputs-and-outputs-with-openai#h_c93188c569" target="_blank" rel="noreferrer">share evaluation and fine-tuning data</a> with OpenAI before creating the job</li></ul><h3 id="structured-outputs-json-schema" tabindex="-1">Structured Outputs JSON schema <a class="header-anchor" href="#structured-outputs-json-schema" aria-label="Permalink to &quot;Structured Outputs JSON schema&quot;">​</a></h3><p>If you&#39;re fine-tuning a model to return <a href="/docs/openai/guides/structured-outputs.html">Structured Outputs</a>, provide the JSON schema being used to format the output. See a valid JSON schema for our security interview use case:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;json_schema&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;json_schema&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;security_assistant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;strict&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;schema&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;object&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;properties&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;compliant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: { </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">&quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;string&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;explanation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: { </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">&quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;string&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;required&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [ </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;compliant&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;explanation&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;additionalProperties&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Generating a JSON schema from a Pydantic model</p><p>To simplify JSON schema generation, start from a <a href="https://docs.pydantic.dev/latest/api/base_model/" target="_blank" rel="noreferrer">Pydantic BaseModel</a> class:</p><ol><li>Define your class</li><li>Use <code>to_strict_json_schema</code> from the OpenAI library to generate a valid schema</li><li>Wrap the schema in a dictionary with <code>type</code> and <code>name</code> keys, and set <code>strict</code> to true</li><li>Take the resulting object and supply it as the <code>response_format</code> in your RFT job</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> openai.lib._pydantic </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> to_strict_json_schema</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pydantic </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> BaseModel</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MyCustomClass</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">BaseModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    age: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Note: Do not use MyCustomClass.model_json_schema() in place of</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># to_strict_json_schema as it is not equivalent</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">response_format </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;json_schema&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    json_schema</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MyCustomClass.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__name__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        strict</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        schema</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">schema</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h3 id="create-a-job-with-the-api" tabindex="-1">Create a job with the API <a class="header-anchor" href="#create-a-job-with-the-api" aria-label="Permalink to &quot;Create a job with the API&quot;">​</a></h3><p>Configuring a job with the API has a lot of moving parts, so many users prefer to configure them in the <a href="/finetune.html">fine-tuning dashboard UI</a>. However, here&#39;s a complete API request to kick off a fine-tune job with all the configuration we&#39;ve set up in this guide so far:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">curl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://api.openai.com/v1/fine_tuning/jobs</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Content-Type: application/json&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Authorization: Bearer </span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$OPENAI_API_KEY</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;{</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;training_file&quot;: &quot;file-2STiufDaGXWCnT6XUBUEHW&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;validation_file&quot;: &quot;file-4TcgH85ej7dFCjZ1kThCYb&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;model&quot;: &quot;o4-mini-2025-04-16&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  &quot;method&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;type&quot;: &quot;reinforcement&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;reinforcement&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      &quot;grader&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;type&quot;: &quot;multi&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;graders&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          &quot;explanation&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;name&quot;: &quot;Explanation text grader&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;type&quot;: &quot;score_model&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;input&quot;: [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                &quot;role&quot;: &quot;user&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                &quot;type&quot;: &quot;message&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                &quot;content&quot;: &quot;# Overview\\n\\nEvaluate the accuracy of the model-generated answer based on the \\nCopernicus Product Security Policy and an example answer. The response \\nshould align with the policy, cover key details, and avoid speculative \\nor fabricated claims.\\n\\nAlways respond with a single floating point number 0 through 1,\\nusing the grading criteria below.\\n\\n## Grading Criteria:\\n- **1.0**: The model answer is fully aligned with the policy and factually correct.\\n- **0.75**: The model answer is mostly correct but has minor omissions or slight rewording that does not change meaning.\\n- **0.5**: The model answer is partially correct but lacks key details or contains speculative statements.\\n- **0.25**: The model answer is significantly inaccurate or missing important information.\\n- **0.0**: The model answer is completely incorrect, hallucinates policy details, or is irrelevant.\\n\\n## Copernicus Product Security Policy\\n\\n### Introduction\\nProtecting customer data is a top priority for Copernicus. Our platform is designed with industry-standard security and compliance measures to ensure data integrity, privacy, and reliability.\\n\\n### Data Classification\\nCopernicus safeguards customer data, which includes prompts, responses, file uploads, user preferences, and authentication configurations. Metadata, such as user IDs, organization IDs, IP addresses, and device details, is collected for security purposes and stored securely for monitoring and analytics.\\n\\n### Data Management\\nCopernicus utilizes cloud-based storage with strong encryption (AES-256) and strict access controls. Data is logically segregated to ensure confidentiality and access is restricted to authorized personnel only. Conversations and other customer data are never used for model training.\\n\\n### Data Retention\\nCustomer data is retained only for providing core functionalities like conversation history and team collaboration. Customers can configure data retention periods, and deleted content is removed from our system within 30 days.\\n\\n### User Authentication &amp; Access Control\\nUsers authenticate via Single Sign-On (SSO) using an Identity Provider (IdP). Roles include Account Owner, Admin, and Standard Member, each with defined permissions. User provisioning can be automated through SCIM integration.\\n\\n### Compliance &amp; Security Monitoring\\n- **Compliance API**: Logs interactions, enabling data export and deletion.\\n- **Audit Logging**: Ensures transparency for security audits.\\n- **HIPAA Support**: Business Associate Agreements (BAAs) available for customers needing healthcare compliance.\\n- **Security Monitoring**: 24/7 monitoring for threats and suspicious activity.\\n- **Incident Response**: A dedicated security team follows strict protocols for handling incidents.\\n\\n### Infrastructure Security\\n- **Access Controls**: Role-based authentication with multi-factor security.\\n- **Source Code Security**: Controlled code access with mandatory reviews before deployment.\\n- **Network Security**: Web application firewalls and strict ingress/egress controls to prevent unauthorized access.\\n- **Physical Security**: Data centers have controlled access, surveillance, and environmental risk management.\\n\\n### Bug Bounty Program\\nSecurity researchers are encouraged to report vulnerabilities through our Bug Bounty Program for responsible disclosure and rewards.\\n\\n### Compliance &amp; Certifications\\nCopernicus maintains compliance with industry standards, including SOC 2 and GDPR. Customers can access security reports and documentation via our Security Portal.\\n\\n### Conclusion\\nCopernicus prioritizes security, privacy, and compliance. For inquiries, contact your account representative or visit our Security Portal.\\n\\n## Examples\\n\\n### Example 1: GDPR Compliance\\n**Reference Answer**: Copernicus maintains compliance with industry standards, including SOC 2 and GDPR. Customers can access security reports and documentation via our Security Portal.\\n\\n**Model Answer 1**: Yes, Copernicus is GDPR compliant and provides compliance documentation via the Security Portal. \\n**Score: 1.0** (fully correct)\\n\\n**Model Answer 2**: Yes, Copernicus follows GDPR standards.\\n**Score: 0.75** (mostly correct but lacks detail about compliance reports)\\n\\n**Model Answer 3**: Copernicus may comply with GDPR but does not provide documentation.\\n**Score: 0.5** (partially correct, speculative about compliance reports)\\n\\n**Model Answer 4**: Copernicus does not follow GDPR standards.\\n**Score: 0.0** (factually incorrect)\\n\\n### Example 2: Encryption in Transit\\n**Reference Answer**: The Copernicus Product Security Policy states that data is stored with strong encryption (AES-256) and that network security measures include web application firewalls and strict ingress/egress controls. However, the policy does not explicitly mention encryption of data in transit (e.g., TLS encryption). A review is needed to confirm whether data transmission is encrypted.\\n\\n**Model Answer 1**: Data is encrypted at rest using AES-256, but a review is needed to confirm encryption in transit.\\n**Score: 1.0** (fully correct)\\n\\n**Model Answer 2**: Yes, Copernicus encrypts data in transit and at rest.\\n**Score: 0.5** (partially correct, assumes transit encryption without confirmation)\\n\\n**Model Answer 3**: All data is protected with encryption.\\n**Score: 0.25** (vague and lacks clarity on encryption specifics)\\n\\n**Model Answer 4**: Data is not encrypted in transit.\\n**Score: 0.0** (factually incorrect)\\n\\nReference Answer: {{item.explanation}}\\nModel Answer: {{sample.output_json.explanation}}\\n&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            ],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;model&quot;: &quot;gpt-4o-2024-08-06&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          &quot;compliant&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;name&quot;: &quot;compliant&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;type&quot;: &quot;string_check&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;reference&quot;: &quot;{{item.compliant}}&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;operation&quot;: &quot;eq&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;input&quot;: &quot;{{sample.output_json.compliant}}&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;calculate_output&quot;: &quot;0.5 * compliant + 0.5 * explanation&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      &quot;response_format&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;type&quot;: &quot;json_schema&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;json_schema&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          &quot;name&quot;: &quot;security_assistant&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          &quot;strict&quot;: true,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          &quot;schema&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;type&quot;: &quot;object&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;properties&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              &quot;compliant&quot;: { </span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                &quot;type&quot;: &quot;string&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              &quot;explanation&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                &quot;type&quot;: &quot;string&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;required&quot;: [</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              &quot;compliant&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">              &quot;explanation&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            ],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;additionalProperties&quot;: false</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">          }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      &quot;hyperparameters&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;reasoning_effort&quot;: &quot;medium&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}&#39;</span></span></code></pre></div><p>This request returns a <a href="/docs/api-reference/fine-tuning/object.html">fine-tuning job object</a>, which includes a job <code>id</code>. Use this ID to monitor the progress of your job and retrieve the fine-tuned model when the job is complete.</p><p>To qualify for <a href="/docs/pricing.html#fine-tuning">data sharing inference pricing</a>, make sure to <a href="https://help.openai.com/en/articles/10306912-sharing-feedback-evaluation-and-fine-tuning-data-and-api-inputs-and-outputs-with-openai#h_c93188c569" target="_blank" rel="noreferrer">share evaluation and fine-tuning data</a> with OpenAI before creating the job. You can verify the job was marked as shared by confirming <code>shared_with_openai</code> is set to <code>true</code>.</p><h3 id="monitoring-your-fine-tune-job" tabindex="-1">Monitoring your fine-tune job <a class="header-anchor" href="#monitoring-your-fine-tune-job" aria-label="Permalink to &quot;Monitoring your fine-tune job&quot;">​</a></h3><p>Fine-tuning jobs take some time to complete, and RFT jobs tend to take longer than SFT or DPO jobs. To monitor the progress of your fine-tune job, use the <a href="/finetune.html">fine-tuning dashboard</a> or the <a href="/docs/api-reference/fine-tuning.html">API</a>.</p><h4 id="reward-metrics" tabindex="-1">Reward metrics <a class="header-anchor" href="#reward-metrics" aria-label="Permalink to &quot;Reward metrics&quot;">​</a></h4><p>For reinforcement fine-tuning jobs, the primary metrics are the per-step <strong>reward</strong> metrics. These metrics indicate how well your model is performing on the training data. They&#39;re calculated by the graders you defined in your job configuration. These are two separate top-level reward metrics:</p><ul><li><code>train_reward_mean</code>: The average reward across the samples taken from all datapoints in the current step. Because the specific datapoints in a batch change with each step, <code>train_reward_mean</code> values across different steps are not directly comparable and the specific values can fluctuate drastically from step to step.</li><li><code>valid_reward_mean</code>: The average reward across the samples taken from all datapoints in the validation set, which is a more stable metric.</li></ul><p><img src="https://cdn.openai.com/API/images/guides/RFT_Reward_Chart.png" alt="Reward Metric Graph"></p><p>Find a full description of all training metrics in the <a href="#training-metrics">training metrics</a> section.</p><h4 id="pausing-and-resuming-jobs" tabindex="-1">Pausing and resuming jobs <a class="header-anchor" href="#pausing-and-resuming-jobs" aria-label="Permalink to &quot;Pausing and resuming jobs&quot;">​</a></h4><p>To evaluate the current state of the model when your job is only partially finished, <strong>pause</strong> the job to stop the training process and produce a checkpoint at the current step. You can use this checkpoint to evaluate the model on a held-out test set. If the results look good, <strong>resume</strong> the job to continue training from that checkpoint. Learn more in <a href="#pausing-and-resuming-jobs">pausing and resuming jobs</a>.</p><h4 id="evals-integration" tabindex="-1">Evals integration <a class="header-anchor" href="#evals-integration" aria-label="Permalink to &quot;Evals integration&quot;">​</a></h4><p>Reinforcement fine-tuning jobs are integrated with our <a href="/docs/openai/guides/evals.html">evals product</a>. When you make a reinforcement fine-tuning job, a new eval is automatically created and associated with the job. As validation steps are performed, we combine the input prompts, model samples, and grader outputs to make a new <a href="/docs/openai/guides/evals.html#creating-an-eval-run">eval run</a> for that step.</p><p>Learn more about the evals integration in the <a href="#evals-integration-details">appendix</a> section below.</p><h2 id="evaluate-the-results" tabindex="-1">Evaluate the results <a class="header-anchor" href="#evaluate-the-results" aria-label="Permalink to &quot;Evaluate the results&quot;">​</a></h2><p>By the time your fine-tuning job finishes, you should have a decent idea of how well the model is performing based on the mean reward value on the validation set. However, it&#39;s possible that the model has either <em>overfit</em> to the training data or has learned to <a href="https://en.wikipedia.org/wiki/Reward_hacking" target="_blank" rel="noreferrer">reward hack</a> your grader, which allows it to produce high scores without actually being correct. Before deploying your model, inspect its behavior on a representative set of prompts to ensure it behaves how you expect.</p><p>Understanding the model&#39;s behavior can be done quickly by inspecting the evals associated with the fine-tuning job. Specifically, pay close attention to the run made for the final training step to see the end model&#39;s behavior. You can also use the evals product to compare the final run to earlier runs and see how the model&#39;s behavior has changed over the course of training.</p><h3 id="try-using-your-fine-tuned-model" tabindex="-1">Try using your fine-tuned model <a class="header-anchor" href="#try-using-your-fine-tuned-model" aria-label="Permalink to &quot;Try using your fine-tuned model&quot;">​</a></h3><p>Evaluate your newly optimized model by using it! When the fine-tuned model finishes training, use its ID in either the <a href="/docs/api-reference/responses.html">Responses</a> or <a href="/docs/api-reference/chat.html">Chat Completions</a> API, just as you would an OpenAI base model.</p><p>Use your model in the Playground</p><ol><li>Navigate to your fine-tuning job in <a href="https://platform.openai.com/finetune" target="_blank" rel="noreferrer">the dashboard</a>.</li><li>In the right pane, navigate to <strong>Output model</strong> and copy the model ID. It should start with <code>ft:…</code></li><li>Open the <a href="https://platform.openai.com/playground" target="_blank" rel="noreferrer">Playground</a>.</li><li>In the <strong>Model</strong> dropdown menu, paste the model ID. Here, you should also see other fine-tuned models you&#39;ve created.</li><li>Run some prompts and see how your fine-tuned performs!</li></ol><p>Use your model with an API call</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">curl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> https://api.openai.com/v1/responses</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Content-Type: application/json&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -H</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Authorization: Bearer </span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">$OPENAI_API_KEY</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> \\</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;{</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;model&quot;: &quot;ft:gpt-4.1-nano-2025-04-14:openai::BTz2REMH&quot;,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;input&quot;: &quot;What is 4+4?&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  }&#39;</span></span></code></pre></div><h3 id="use-checkpoints-if-needed" tabindex="-1">Use checkpoints if needed <a class="header-anchor" href="#use-checkpoints-if-needed" aria-label="Permalink to &quot;Use checkpoints if needed&quot;">​</a></h3><p>Checkpoints are models you can use that are created before the final step of the training process. For RFT, OpenAI creates a full model checkpoint at each validation step and keeps the three with the highest <code>valid_reward_mean</code> scores. Checkpoints are useful for evaluating the model at different points in the training process and comparing performance at different steps.</p><p>Find checkpoints in the dashboard</p><ol><li>Navigate to the <a href="https://platform.openai.com/finetune" target="_blank" rel="noreferrer">fine-tuning dashboard</a>.</li><li>In the left panel, select the job you want to investigate. Wait until it succeeds.</li><li>In the right panel, scroll to the list of checkpoints.</li><li>Hover over any checkpoint to see a link to launch in the Playground.</li><li>Test the checkpoint model&#39;s behavior by prompting it in the Playground.</li></ol><p>Query the API for checkpoints</p><ol><li>Wait until a job succeeds, which you can verify by <a href="/docs/api-reference/fine-tuning/retrieve.html">querying the status of a job</a>.</li><li><a href="/docs/api-reference/fine-tuning/list-checkpoints.html">Query the checkpoints endpoint</a> with your fine-tuning job ID to access a list of model checkpoints for the fine-tuning job.</li><li>Find the <code>fine_tuned_model_checkpoint</code> field for the name of the model checkpoint.</li><li>Use this model just like you would the final fine-tuned model.</li></ol><p>The checkpoint object contains <code>metrics</code> data to help you determine the usefulness of this model. As an example, the response looks like this:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;object&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;fine_tuning.job.checkpoint&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;created_at&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1519129973</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;fine_tuned_model_checkpoint&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ft:gpt-3.5-turbo-0125:my-org:custom-suffix:96olL566:ckpt-step-2000&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;metrics&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;full_valid_loss&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.134</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;full_valid_mean_token_accuracy&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.874</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;fine_tuning_job_id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ftjob-abc123&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;step_number&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2000</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>Each checkpoint specifies:</p><ul><li><code>step_number</code>: The step at which the checkpoint was created (where each epoch is number of steps in the training set divided by the batch size)</li><li><code>metrics</code>: An object containing the metrics for your fine-tuning job at the step when the checkpoint was created</li></ul><h2 id="next-steps" tabindex="-1">Next steps <a class="header-anchor" href="#next-steps" aria-label="Permalink to &quot;Next steps&quot;">​</a></h2><p>Now that you know the basics of reinforcement fine-tuning, explore other fine-tuning methods.</p><p>[</p><p>Supervised fine-tuning</p><p>Fine-tune a model by providing correct outputs for sample inputs.</p><p>](/docs/openai/guides/supervised-fine-tuning)[</p><p>Vision fine-tuning</p><p>Learn to fine-tune for computer vision with image inputs.</p><p>](/docs/openai/guides/vision-fine-tuning)[</p><p>Direct preference optimization</p><p>Fine-tune a model using direct preference optimization (DPO).</p><p>](/docs/openai/guides/direct-preference-optimization)</p><h2 id="appendix" tabindex="-1">Appendix <a class="header-anchor" href="#appendix" aria-label="Permalink to &quot;Appendix&quot;">​</a></h2><h3 id="training-metrics" tabindex="-1">Training metrics <a class="header-anchor" href="#training-metrics" aria-label="Permalink to &quot;Training metrics&quot;">​</a></h3><p>Reinforcement fine-tuning jobs publish per-step training metrics as <a href="/docs/api-reference/fine-tuning/event-object.html">fine-tuning events</a>. Pull these metrics through the <a href="/docs/api-reference/fine-tuning/list-events.html">API</a> or view them as graphs and charts in the <a href="/finetune.html">fine-tuning dashboard</a>.</p><p>Learn more about training metrics below.</p><p>Full example training metrics</p><p>Below is an example metric event from a real reinforcement fine-tuning job. The various fields in this payload will be discussed in the following sections.</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;object&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;fine_tuning.job.event&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;ftevent-Iq5LuNLDsac1C3vzshRBuBIy&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;created_at&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1746679539</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;level&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;info&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;message&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Step 10/20 , train mean reward=0.42, full validation mean reward=0.68, full validation mean parse error=0.00&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;step&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;usage&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;graders&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;basic_model_grader&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;score_model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;gpt-4o-2024-08-06&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_prompt_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">241.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_prompt_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">241.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_prompt_tokens_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">120741.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_prompt_tokens_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4820.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_completion_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">138.52694610778443</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_completion_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">140.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_completion_tokens_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">69402.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_completion_tokens_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2810.0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          ],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;samples&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;train_reasoning_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3330.017964071856</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;valid_reasoning_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1948.9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;train_reasoning_tokens_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1668339.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;valid_reasoning_tokens_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">38978.0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;errors&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;graders&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;basic_model_grader&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;score_model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_other_error_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_other_error_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_other_error_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_other_error_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_sample_parse_error_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_sample_parse_error_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_sample_parse_error_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_sample_parse_error_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_invalid_variable_error_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_invalid_variable_error_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_invalid_variable_error_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_invalid_variable_error_count&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          ]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;scores&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;graders&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;basic_model_grader&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;score_model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_reward_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4471057884231537</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_reward_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.675</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          ],</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;train_reward_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4215686274509804</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;valid_reward_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.675</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;timing&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;step&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;eval&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">101.69386267662048</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;sampling&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">226.82190561294556</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;training&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">402.43121099472046</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;full_iteration&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">731.5038568973541</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;graders&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: [</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;name&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;basic_model_grader&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;score_model&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;train_execution_latency_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.6894934929297594</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              &quot;valid_execution_latency_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4.141402995586395</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          ]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;total_steps&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;train_mean_reward&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4215686274509804</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;reasoning_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3330.017964071856</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;completion_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3376.0019607843137</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;full_valid_mean_reward&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.675</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;mean_unresponsive_rewards&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;model_graders_token_usage&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">          &quot;gpt-4o-2024-08-06&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;eval_cached_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;eval_prompt_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4820</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;train_cached_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;train_prompt_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">120741</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;eval_completion_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2810</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            &quot;train_completion_tokens&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">69402</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">          }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;full_valid_mean_parse_error&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        &quot;valid_reasoning_tokens_mean&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1948.9</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">      },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">      &quot;type&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;metrics&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    },</span></span></code></pre></div><p>Score metrics</p><p>The top-level metrics to watch are <code>train_reward_mean</code> and <code>valid_reward_mean</code>, which indicate the average reward assigned by your graders across all samples in the training and validation datasets, respectively.</p><p>Additionally, if you use a <a href="/docs/api-reference/graders/multi.html">multi-grader</a> configuration, per-grader train and validation reward metrics will be published as well. These metrics are included under the <code>event.data.scores</code> object in the fine-tuning events object, with one entry per grader. The per-grader metrics are useful for understanding how the model is performing on each individual grader, and can help you identify if the model is overfitting to one grader or another.</p><p>From the fine-tuning dashboard, the individual grader metrics will be displayed in their own graph below the overall <code>train_reward_mean</code> and <code>valid_reward_mean</code> metrics.</p><p><img src="https://cdn.openai.com/API/images/guides/RFT_MultiReward_Chart.png" alt="Per-Grader Reward Metric Graph"></p><p>Usage metrics</p><p>An important characteristic of a reasoning model is the number of reasoning tokens it uses before responding to a prompt. Often, during training, the model will drastically change the average number of reasoning tokens it uses to respond to a prompt. This is a sign that the model is changing its behavior in response to the reward signal. The model may learn to use fewer reasoning tokens to achieve the same reward, or it may learn to use more reasoning tokens to achieve a higher reward.</p><p>You can monitor the <code>train_reasoning_tokens_mean</code> and <code>valid_reasoning_tokens_mean</code> metrics to see how the model is changing its behavior over time. These metrics are the average number of reasoning tokens used by the model to respond to a prompt in the training and validation datasets, respectively. You can also view the mean reasoning token count in the fine-tuning dashboard under the &quot;Reasoning Tokens&quot; chart.</p><p><img src="https://cdn.openai.com/API/images/guides/RFT_ReasoningTokens_Chart.png" alt="Reasoning Tokens Metric Graph"></p><p>If you are using <a href="/docs/openai/guides/graders.html#model-graders">model graders</a>, you will likely want to monitor the token usage of these graders. Per-grader token usage statistics are available under the <code>event.data.usage.graders</code> object, and are broken down into:</p><ul><li><code>train_prompt_tokens_mean</code></li><li><code>train_prompt_tokens_count</code></li><li><code>train_completion_tokens_mean</code></li><li><code>train_completion_tokens_count</code>.</li></ul><p>The <code>_mean</code> metrics represent the average number of tokens used by the grader to process all prompts in the current step, while the <code>_count</code> metrics represent the total number of tokens used by the grader across all samples in the current step. The per-step token usage is also displayed on the fine-tuning dashboard under the &quot;Grading Token Usage&quot; chart.</p><p><img src="https://cdn.openai.com/API/images/guides/RFT_ModelGraderTokenUsage.png" alt="Model Grader Token Usage"></p><p>Timing metrics</p><p>We include various metrics that help you understand how long each step of the training process is taking and how different parts of the training process are contributing to the per-step timing.</p><p>These metrics are available under the <code>event.data.timing</code> object, and are broken down into <code>step</code> and <code>graders</code> fields.</p><p>The <code>step</code> field contains the following metrics:</p><ul><li><code>sampling</code>: The time taken to sample the model outputs (rollouts) for the current step.</li><li><code>training</code>: The time taken to train the model (backpropagation) for the current step.</li><li><code>eval</code>: The time taken to evaluate the model on the full validation set.</li><li><code>full_iteration</code>: The total time taken for the current step, including the above 3 metrics plus any additional overhead.</li></ul><p>The step timing metrics are also displayed on the fine-tuning dashboard under the &quot;Per Step Duration&quot; chart.</p><p><img src="https://cdn.openai.com/API/images/guides/RFT_PerStepDuration2.png" alt="Per Step Duration Graph"></p><p>The <code>graders</code> field contains timing information that details the time taken to execute each grader for the current step. Each grader will have its own timing under the <code>train_execution_latency_mean</code> and <code>valid_execution_latency_mean</code> metrics, which represent the average time taken to execute the grader on the training and validation datasets, respectively.</p><p>Graders are executed in parallel with a concurrency limit, so it is not always clear how individual grader latency adds up to the total time taken for grading. However, it is generally true that graders which take longer to execute individually will cause a job to execute more slowly. This means that slower model graders will cause the job to take longer to complete, and more expensive python code will do the same. The fastest graders generally are <code>string_check</code> and <code>text_similarity</code> as those are executed local to the training loop.</p><h3 id="evals-integration-details" tabindex="-1">Evals integration details <a class="header-anchor" href="#evals-integration-details" aria-label="Permalink to &quot;Evals integration details&quot;">​</a></h3><p>Reinforcement fine-tuning jobs are directly integrated with our <a href="/docs/openai/guides/evals.html">evals product</a>. When you make a reinforcement fine-tuning job, a new eval is automatically created and associated with the job.</p><p>As validation steps are performed, the input prompts, model samples, grader outputs, and more metadata will be combined to make a new <a href="/docs/openai/guides/evals.html#creating-an-eval-run">eval run</a> for that step. At the end of the job, you will have one run for each validation step. This allows you to compare the performance of the model at different steps, and to see how the model&#39;s behavior has changed over the course of training.</p><p>You can find the eval associated with your fine-tuning job by viewing your job on the fine-tuning dashboard, or by finding the <code>eval_id</code> field on the <a href="/docs/api-reference/fine-tuning/object.html">fine-tuning job object</a>.</p><p>The evals product is useful for inspecting the outputs of the model on specific datapoints, to get an understanding for how the model is behaving in different scenarios. It can help you figure out which slice of your dataset the model is performing poorly on which can help you identify areas for improvement in your training data.</p><p>The evals product can also help you find areas of improvement for your graders by finding areas where the grader is either overly lenient or overly harsh on the model outputs.</p><h3 id="pausing-and-resuming-jobs-1" tabindex="-1">Pausing and resuming jobs <a class="header-anchor" href="#pausing-and-resuming-jobs-1" aria-label="Permalink to &quot;Pausing and resuming jobs&quot;">​</a></h3><p>You can pause a fine-tuning job at any time by using the <a href="/docs/api-reference/fine-tuning/pause.html">fine-tuning jobs API</a>. Calling the pause API will tell the training process to create a new model snapshot, stop training, and put the job into a &quot;Paused&quot; state. The model snapshot will go through a normal safety screening process after which it will be available for you to use throughout the OpenAI platform as a normal fine-tuned model.</p><p>If you wish to continue the training process for a paused job, you can do so by using the <a href="/docs/api-reference/fine-tuning/resume.html">fine-tuning jobs API</a>. This will resume the training process from the last checkpoint created when the job was paused and will continue training until the job is either completed or paused again.</p><h3 id="grading-with-tools" tabindex="-1">Grading with Tools <a class="header-anchor" href="#grading-with-tools" aria-label="Permalink to &quot;Grading with Tools&quot;">​</a></h3><p>If you are training your model to <a href="/docs/openai/guides/function-calling.html">perform tool calls</a>, you will need to:</p><ol><li>Provide the set of tools available for your model to call on each datapoint in the RFT training dataset. More info here in the <a href="/docs/api-reference/fine-tuning/reinforcement-input.html">dataset API reference</a>.</li><li>Configure your grader to assign rewards based on the contents of the tool calls made by the model. Information on grading tools calls can be found <a href="/docs/openai/guides/graders/#sample-namespace">here in the grading docs</a></li></ol><h3 id="billing-details" tabindex="-1">Billing details <a class="header-anchor" href="#billing-details" aria-label="Permalink to &quot;Billing details&quot;">​</a></h3><p>Reinforcement fine-tuning jobs are billed based on the amount of time spent training, as well as the number of tokens used by the model during training. We only bill for time spent in the core training loop, not for time spent preparing the training data, validating datasets, waiting in queues, running safety evals, or other overhead.</p><p>Details on exactly how we bill for reinforcement fine-tuning jobs can be found in this <a href="https://help.openai.com/en/articles/11323177-billing-guide-for-the-reinforcement-fine-tuning-api" target="_blank" rel="noreferrer">help center article</a>.</p><h3 id="training-errors" tabindex="-1">Training errors <a class="header-anchor" href="#training-errors" aria-label="Permalink to &quot;Training errors&quot;">​</a></h3><p>Reinforcement fine-tuning is a complex process with many moving parts, and there are many places where things can go wrong. We publish various error metrics to help you understand what is going wrong in your job, and how to fix it. In general, we try to avoid failing a job entirely unless a very serious error occurs. When errors do occur, they often happen during the grading step. Errors during grading often happen either to the model outputting a sample that the grader doesn&#39;t know how to handle, the grader failing to execute properly due to some sort of system error, or due to a bug in the grading logic itself.</p><p>The error metrics are available under the <code>event.data.errors</code> object, and are aggregated into counts and rates rolled up per-grader. We also display rates and counts of errors on the fine-tuning dashboard.</p><p>Grader errors</p><h4 id="generic-grading-errors" tabindex="-1">Generic grading errors <a class="header-anchor" href="#generic-grading-errors" aria-label="Permalink to &quot;Generic grading errors&quot;">​</a></h4><p>The grader errors are broken down into the following categories, and they exist in both <code>train_</code> (for training data) and <code>valid_</code> (for validation data) versions:</p><ul><li><code>sample_parse_error_mean</code>: The average number of samples that failed to parse correctly. This often happens when the model fails to output valid JSON or adhere to a provided response format correctly. A small percentage of these errors, especially early in the training process, is normal. If you see a large number of these errors, it is likely that the response format of the model is not configured correctly or that your graders are misconfigured and looking for incorrect fields.</li><li><code>invalid_variable_error_mean</code>: These errors occur when you attempt to reference a variable via a template that cannot be found either in the current datapoint or in the current model sample. This can happen if the model fails to provide output in the correct response format, or if your grader is misconfigured.</li><li><code>other_error_mean</code>: This is a catch-all for any other errors that occur during grading. These errors are often caused by bugs in the grading logic itself, or by system errors that occur during grading.</li></ul><h4 id="python-grading-errors" tabindex="-1">Python grading errors <a class="header-anchor" href="#python-grading-errors" aria-label="Permalink to &quot;Python grading errors&quot;">​</a></h4><ul><li><code>python_grader_server_error_mean</code>: These errors occur when our system for executing python graders in a remote sandbox experiences system errors. This normally happens due to reasons outside of your control, like networking failures or system outages. If you see a large number of these errors, it is likely that there is a system issue that is causing the errors. You can check the <a href="https://status.openai.com/" target="_blank" rel="noreferrer">OpenAI status page</a> for more information on any ongoing issues.</li><li><code>python_grader_runtime_error_mean</code>: These errors occur when the python grader itself fails to execute properly. This can happen for a variety of reasons, including bugs in the grading logic, or if the grader is trying to access a variable that doesn&#39;t exist in the current context. If you see a large number of these errors, it is likely that there is a bug in your grading logic that needs to be fixed. If a large enough number of these errors occur, the job will fail and we will show you a sampling of tracebacks from the failed graders.</li></ul><h4 id="model-grading-errors" tabindex="-1">Model grading errors <a class="header-anchor" href="#model-grading-errors" aria-label="Permalink to &quot;Model grading errors&quot;">​</a></h4><ul><li><code>model_grader_server_error_mean</code>: These errors occur when we fail to sample from a model grader. This can happen for a variety of reasons, but generally means that either the model grader was misconfigured, that you are attempting to use a model that is not available to your organization, or that there is a system issue that is happening at OpenAI.</li></ul>`,136))])}const y=n(r,[["render",h]]);export{E as __pageData,y as default};
