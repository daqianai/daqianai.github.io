import{_ as e,c as t,o as a}from"./chunks/framework.DDIT__tB.js";const h=JSON.parse('{"title":"","description":"","frontmatter":{"layout":"home","hero":{"name":"Eval","text":"","tagline":null,"actions":[{"theme":"alt","text":"Berkeley Leaderboard","link":"https://gorilla.cs.berkeley.edu/leaderboard.html"},{"theme":"alt","text":"leaderboard","link":"https://medium.com/@olga.zem/exploring-llm-leaderboards-8527eac97431"},{"theme":"alt","text":"OpenAI Evals","link":"https://github.com/openai/evals/"}]},"features":[{"title":"OpenAI Evals <br>@OpenAI","link":"https://github.com/openai/evals/","details":"Evals provide a framework for evaluating large language models (LLMs) or systems built using LLMs. We offer an existing registry of evals to test different dimensions of OpenAI models and the ability to write your own custom evals for use cases you care about. You can also use your data to build private evals which represent the common LLMs patterns in your workflow without exposing any of that data publicly"},{"title":"Gorilla <br>@berkeley","link":"https://github.com/ShishirPatil/gorilla","details":"With Gorilla, we are the first to demonstrate how to use LLMs to invoke 1,600+ (and growing) API calls accurately while reducing hallucination. This repository contains inference code for running Gorilla finetuned models, evaluation code for reproducing results from our paper, and APIBench - the largest collection of APIs, curated and easy to be trained on!"},{"title":"DeepEval  <br>@Confident AI","link":"https://github.com/confident-ai/deepeval","details":"DeepEval is a simple-to-use, open-source LLM evaluation framework, for evaluating and testing large-language model systems. It is similar to Pytest but specialized for unit testing LLM outputs. DeepEval incorporates the latest research to evaluate LLM outputs based on metrics such as G-Eval, hallucination, answer relevancy, RAGAS, etc., which uses LLMs and various other NLP models that runs locally on your machine for evaluation."}]},"headers":[],"relativePath":"eval/index.md","filePath":"eval/index.md","lastUpdated":1748437317000}'),o={name:"eval/index.md"};function l(i,s,r,n,d,u){return a(),t("div")}const p=e(o,[["render",l]]);export{h as __pageData,p as default};
